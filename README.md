# Thrombosis-Research (Repo. under contruction)

The repository briefly describes the publication I co-authored under Dr. Anass Bouchnita at University of Texas at El Paso where we utilised Deep learning and Machine Learning oriented thrombosis classification research.

## Introduction
A blood clot forms in blood veins as a result of the complex process of blood coagulation, which involves biochemical reactions, blood flow, and injured wall. 
Shear stress, flow rate, the presence of platelets, and other clotting factors are among the many variables that interact in this tightly controlled process.
Thrombin generation assays are used to assess the risk of bleeding. However, they are hard to interpret and do not consider in vivo conditions.

## Objective
In this study, we propose a new method for the assessment of the risk of bleeding based on thrombin generation assays using machine learning and mathematical models.
We specifically suggest the fast and accurate determination of the thrombin production levels that initiate coagulation using machine learning models trained with numerical simulations of CFD models.

## Methodology

### Computational Fluid Mechanics Equations
To model thrombus development under flow, a number of methods have been used, including ordinary differentiation equation (ODE), continuum-based modeling, mixture theory, and multiscale modeling, among others.
We used a computational fluid dynamics (CFD) model for coagulation initiation1, and at the same time calculated the following thrombin generation parameters using an ODE Model: 
(i) the lag time, 
(ii) the peak thrombin concentration,
(iii) the time to peak, and (iv) the endogenous thrombin potential (ETP). 
The deep learning model was trained using numerical simulations of the CFD model (ETP).
In the CFD model, we describe blood flow as Newtonian incompressible flow using the Navier-Stokes equation:

<img src="https://github.com/user-attachments/assets/08167575-8d5a-4cd2-a2d0-c0d8cef3b09d" alt="Image Description" width="700" height="100"/>

    import numpy as np
    import scipy.sparse as sp
    import scipy.sparse.linalg as spla

    Parameters
    rho = 1.0   # density
    mu = 1.0    # viscosity
    K_f = 1.0   # constant related to the porous medium
    Nx, Ny = 50, 50  # Grid points
    Lx, Ly = 1.0, 1.0  # Domain size
    dx, dy = Lx / Nx, Ly / Ny
    dt = 0.01  # Time step
    u = np.zeros((Nx, Ny, 2))  # Velocity field, u[..., 0] is u_x, u[..., 1] is u_y
    p = np.zeros((Nx, Ny))  # Pressure field

    Time-stepping loop
    for t in range(100):
        Compute the intermediate velocity
        u_star = u.copy()
    
    # u_star = u - dt * (non-linear term + pressure gradient)
    for i in range(1, Nx-1):
        for j in range(1, Ny-1):
            convective_term_x = (u[i,j,0] * (u[i+1,j,0] - u[i-1,j,0]) / (2*dx) + 
                                 u[i,j,1] * (u[i,j+1,0] - u[i,j-1,0]) / (2*dy))
            convective_term_y = (u[i,j,0] * (u[i+1,j,1] - u[i-1,j,1]) / (2*dx) + 
                                 u[i,j,1] * (u[i,j+1,1] - u[i,j-1,1]) / (2*dy))
            
            u_star[i,j,0] -= dt * (convective_term_x + (1/rho) * (p[i+1,j] - p[i-1,j]) / (2*dx))
            u_star[i,j,1] -= dt * (convective_term_y + (1/rho) * (p[i,j+1] - p[i,j-1]) / (2*dy))

    # Solve for pressure correction
    div_u = (u_star[2:,1:-1,0] - u_star[:-2,1:-1,0]) / (2*dx) + (u_star[1:-1,2:,1] - u_star[1:-1,:-2,1]) / (2*dy)
    p_correction = spla.spsolve(laplacian_matrix, div_u.flatten())
    p_correction = p_correction.reshape((Nx-2, Ny-2))
    
    # Update the velocity field
    u[1:-1,1:-1,0] = u_star[1:-1,1:-1,0] - dt * (p_correction[1:, :] - p_correction[:-1, :]) / (2*dx)
    u[1:-1,1:-1,1] = u_star[1:-1,1:-1,1] - dt * (p_correction[:, 1:] - p_correction[:, :-1]) / (2*dy)

    Visualization
    import matplotlib.pyplot as plt
    plt.quiver(u[:,:,0], u[:,:,1])
    plt.show()


Blood flow decelerates as it crosses the porous medium, whose porosity depends on the production of fibrin polymer. The production of the latter is described by solving the PDE system:

<img src="https://github.com/user-attachments/assets/a2ba8d63-2a17-4551-affa-79d926f48aef" alt="Image Description" width="400" height="120"/>
<img src="https://github.com/user-attachments/assets/4c860290-085a-4f3d-8876-ffbbc9e10bb9" alt="Image Description" width="400" height="300"/>

### Deep Learning and Machine Learning for constucting Surogate Model
We develop a surrogate model which consists of an artificial neural network (ANN) that predicts coagulation initiation based on the results of numerical simulations. 
We ran 7675 simulations in total, using 30% to assess the neural network's performance and 70% to train the network.
Simulations are generated by considering random parameters sampled from uniform distributions.
For each simulation, we calculate the thrombin generation parameters: (lag time, ETP, thrombin peak concentration, and time to peak).
Each simulation was given a label of "1" if coagulation started and "0" otherwise.
We consider the thrombin generation parameters as well as blood flow velocity (pressure difference) and the size of the injury site as model inputs.

<img src="https://github.com/user-attachments/assets/2d76078b-3820-4dee-a42f-d8fc7a558dea" alt="Image Description" width="800" height="400"/>



