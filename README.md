# Thrombosis-Research (Repo. under contruction)

The repository briefly describes the publication I co-authored under Dr. Anass Bouchnita at University of Texas at El Paso where we utilised Deep learning and Machine Learning oriented thrombosis classification research. 

My main contribution towards the research involved running machine learning and deep learning algorithms for the purpose of testing the accuracy of the data we had. My work involved performing binary classification to classify the patients into ones who have clotting and the others that do not have clotting based on the feature ‘clot size’ in our dataset, which was computationally generated.

## Introduction
A blood clot forms in blood veins as a result of the complex process of blood coagulation, which involves biochemical reactions, blood flow, and injured wall. 
Shear stress, flow rate, the presence of platelets, and other clotting factors are among the many variables that interact in this tightly controlled process.
Thrombin generation assays are used to assess the risk of bleeding. However, they are hard to interpret and do not consider in vivo conditions.

## Objective
In this study, we propose a new method for the assessment of the risk of bleeding based on thrombin generation assays using machine learning and mathematical models.
We specifically suggest the fast and accurate determination of the thrombin production levels that initiate coagulation using machine learning models trained with numerical simulations of CFD models.

## Methodology

### Computational Fluid Mechanics Equations
To model thrombus development under flow, a number of methods have been used, including ordinary differentiation equation (ODE), continuum-based modeling, mixture theory, and multiscale modeling, among others.
We used a computational fluid dynamics (CFD) model for coagulation initiation1, and at the same time calculated the following thrombin generation parameters using an ODE Model: 
(i) the lag time, 
(ii) the peak thrombin concentration,
(iii) the time to peak, and (iv) the endogenous thrombin potential (ETP). 
The deep learning model was trained using numerical simulations of the CFD model (ETP).
In the CFD model, we describe blood flow as Newtonian incompressible flow using the Navier-Stokes equation:

<img src="https://github.com/user-attachments/assets/08167575-8d5a-4cd2-a2d0-c0d8cef3b09d" alt="Image Description" width="700" height="100"/>

Blood flow decelerates as it crosses the porous medium, whose porosity depends on the production of fibrin polymer. The production of the latter is described by solving the PDE system:

<img src="https://github.com/user-attachments/assets/a2ba8d63-2a17-4551-affa-79d926f48aef" alt="Image Description" width="400" height="120"/><br>
<img src="https://github.com/user-attachments/assets/4c860290-085a-4f3d-8876-ffbbc9e10bb9" alt="Image Description" width="400" height="300"/>

### Deep Learning and Machine Learning for constucting Surogate Model
We develop a surrogate model which consists of an artificial neural network (ANN) that predicts coagulation initiation based on the results of numerical simulations. 
We ran 7675 simulations in total, using 30% to assess the neural network's performance and 70% to train the network.
Simulations are generated by considering random parameters sampled from uniform distributions.
For each simulation, we calculate the thrombin generation parameters: (lag time, ETP, thrombin peak concentration, and time to peak).
Each simulation was given a label of "1" if coagulation started and "0" otherwise.
We consider the thrombin generation parameters as well as blood flow velocity (pressure difference) and the size of the injury site as model inputs.

<img src="https://github.com/user-attachments/assets/2d76078b-3820-4dee-a42f-d8fc7a558dea" alt="Image Description" width="800" height="400"/>

# Code

    from google.colab import drive
    drive.mount('/content/drive')
    
    import matplotlib.pyplot as plt
    import pandas as pd
    import numpy as np
    
    import tensorflow as tf
    
    newMat = pd.read_csv('/content/drive/MyDrive/Documents/UTEP/3rd Sem/Graduate research new_code/newMat_CSV.csv')
    
    newMat
    
    from sklearn.metrics import accuracy_score
    res = tf.feature_column.categorical_column_with_vocabulary_list("clot_size", [0, 1])
    
    dp = tf.feature_column.numeric_column("dp")
    dx = tf.feature_column.numeric_column("dx")
    LagT = tf.feature_column.numeric_column("LagT")
    ETP = tf.feature_column.numeric_column("ETP")
    Cmax = tf.feature_column.numeric_column("Cmax")
    Tmax = tf.feature_column.numeric_column("Tmax")
    
    from sklearn.model_selection import train_test_split
    x_data = newMat[["dp", "dx", "LagT", "ETP", "Cmax", "Tmax"]]
    y_labels = newMat['clot_size']
    X_train, X_test, y_train, y_test = train_test_split(x_data,y_labels,test_size=0.3,random_state=101)
    X_train, X_test, y_train, y_test = train_test_split(x_data,y_labels,test_size=0.3,random_state=101)
    
    y_train = pd.to_numeric(y_train, downcast='integer')
    y_test = pd.to_numeric(y_test, downcast = 'integer')
    y_train = y_train.astype(int)
    y_test = y_test.astype(int)
    
    feat_cols = [dp, dx, LagT, ETP, Cmax, Tmax]
    
    """# DNN
    ## (500, 250, 100)
    """
    
    input_func=tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_train,
                                                   y=y_train,
                                                   batch_size=200,
                                                   num_epochs=None,
                                                   shuffle=True)
    
    from sklearn import svm, datasets, metrics
    
    model = tf.estimator.LinearClassifier(feature_columns=feat_cols, n_classes=2)
    
    from tensorflow.keras.optimizers import legacy
    
    model = tf.estimator.DNNClassifier(feature_columns=feat_cols, optimizer = legacy.Adam,
                                              hidden_units=[500, 250, 100],
                                              #dropout=0.025,
                                              #activation_fn = tf.nn.softmax,
                                              #optimizer='Adagrad',
                                              n_classes=2)
    
    y_test_n = y_test.to_numpy()
    
    print("Training model...")
    print("LogLoss error (on validation data):")
    validation_errors = []
    for period in range (0, 200):
    # Train the model, starting from the prior state.
        model.train(
        input_fn=input_func,
        steps=500
        )
        pred_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)
        y_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=y_test,batch_size=len(y_test),shuffle=False)
    
        validation_predictions = list(model.predict(input_fn=pred_fn))
        validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])
        validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])
        validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,0)
        validation_log_loss = metrics.log_loss(y_test_n, validation_pred_one_hot)
        print(" period %02d : %0.2f" % (period, validation_log_loss))
        validation_errors.append(validation_log_loss)
    
    final_predictions = model.predict(input_fn=pred_fn)
    final_predictions = np.array([item['class_ids'][0] for item in final_predictions])
    
    accuracy = metrics.accuracy_score(y_test_n, final_predictions)
    print("Final accuracy (on validation data): %0.2f" % accuracy)
    plt.rcParams["figure.figsize"] = (12,10)
    # Output a graph of loss metrics over periods.
    plt.ylabel("LogLoss", fontsize = 20)
    plt.xlabel("Periods", fontsize = 20)
    plt.title("LogLoss vs. Periods (validation)", fontsize = 20)
    plt.plot(validation_errors, 'k', linewidth = 2)
    #plt.legend()
    plt.show()
    
    import seaborn as sns
    plt.rcParams["figure.figsize"] = (12,10)
    
    cm = metrics.confusion_matrix(y_test_n, final_predictions)
    # Normalize the confusion matrix by row (i.e by the number of samples
    # in each class).
    cm_normalized = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
    
    ax = sns.heatmap(cm_normalized, cmap="bone_r")
    ax.set_aspect(1)
    plt.title("Confusion matrix", fontsize = 20)
    plt.ylabel("True label", fontsize = 20)
    plt.xlabel("Predicted label", fontsize = 20)
    plt.show()
    
    # Commented out IPython magic to ensure Python compatibility.
    print("Classification report for classifier %s:\n%s\n"
    #       % (model, metrics.classification_report(y_test_n, final_predictions, labels=[0, 1])))
    
    accuracy = accuracy_score(y_test_n, final_predictions)
    DNN_A = accuracy
    print('Accuracy: {:.2f}%'.format(DNN_A * 100))
    
    """# DNN
    ## (200x100x50)
    """
    
    model_1 = tf.estimator.LinearClassifier(feature_columns=feat_cols, n_classes=2)
    
    model_1 = tf.estimator.DNNClassifier(feature_columns=feat_cols, optimizer = legacy.Adam,
                                              hidden_units=[250, 100, 50],
                                              #dropout=0.025,
                                              #activation_fn = tf.nn.softmax,
                                              #optimizer='Adagrad',
                                              n_classes=2)
    
    print("Training model_1...")
    print("LogLoss error (on validation data):")
    validation_errors = []
    for period in range (0, 200):
    # Train the model_1, starting from the prior state.
        model_1.train(
        input_fn=input_func,
        steps=500
        )
        pred_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)
        y_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=y_test,batch_size=len(y_test),shuffle=False)
    
        validation_predictions = list(model_1.predict(input_fn=pred_fn))
        validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])
        validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])
        validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,0)
        validation_log_loss = metrics.log_loss(y_test_n, validation_pred_one_hot)
        print(" period %02d : %0.2f" % (period, validation_log_loss))
        validation_errors.append(validation_log_loss)
    
    final_predictions = model_1.predict(input_fn=pred_fn)
    final_predictions = np.array([item['class_ids'][0] for item in final_predictions])
    
    accuracy = metrics.accuracy_score(y_test_n, final_predictions)
    print("Final accuracy (on validation data): %0.2f" % accuracy)
    plt.rcParams["figure.figsize"] = (12,10)
    # Output a graph of loss metrics over periods.
    plt.ylabel("LogLoss", fontsize = 20)
    plt.xlabel("Periods", fontsize = 20)
    plt.title("LogLoss vs. Periods (validation)", fontsize = 20)
    plt.plot(validation_errors, 'k', linewidth = 2)
    #plt.legend()
    plt.show()
    
    plt.rcParams["figure.figsize"] = (12,10)
    
    cm = metrics.confusion_matrix(y_test_n, final_predictions)
    # Normalize the confusion matrix by row (i.e by the number of samples
    # in each class).
    cm_normalized = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
    
    ax = sns.heatmap(cm_normalized, cmap="bone_r")
    ax.set_aspect(1)
    plt.title("Confusion matrix", fontsize = 20)
    plt.ylabel("True label", fontsize = 20)
    plt.xlabel("Predicted label", fontsize = 20)
    plt.show()
    
    # Commented out IPython magic to ensure Python compatibility.
    print("Classification report for classifier %s:\n%s\n"
    #       % (model_1, metrics.classification_report(y_test_n, final_predictions, labels=[0, 1])))
    
    accuracy = accuracy_score(y_test_n, final_predictions)
    DNN_B = accuracy
    print('Accuracy: {:.2f}%'.format(DNN_B * 100))
    
    """# DNN
    ## (100, 50 25)
    """
    
    model_2 = tf.estimator.LinearClassifier(feature_columns=feat_cols, n_classes=2)
    
    model_2 = tf.estimator.DNNClassifier(feature_columns=feat_cols, optimizer = legacy.Adam,
                                              hidden_units=[250, 100, 50],
                                              #dropout=0.025,
                                              #activation_fn = tf.nn.softmax,
                                              #optimizer='Adagrad',
                                              n_classes=2)
    
    print("Training model_2...")
    print("LogLoss error (on validation data):")
    validation_errors = []
    for period in range (0, 200):
    # Train the model_2, starting from the prior state.
        model_2.train(
        input_fn=input_func,
        steps=500
        )
        pred_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)
        y_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=y_test,batch_size=len(y_test),shuffle=False)
    
        validation_predictions = list(model_2.predict(input_fn=pred_fn))
        validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])
        validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])
        validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,0)
        validation_log_loss = metrics.log_loss(y_test_n, validation_pred_one_hot)
        print(" period %02d : %0.2f" % (period, validation_log_loss))
        validation_errors.append(validation_log_loss)
    
    final_predictions = model_2.predict(input_fn=pred_fn)
    final_predictions = np.array([item['class_ids'][0] for item in final_predictions])
    
    accuracy = metrics.accuracy_score(y_test_n, final_predictions)
    print("Final accuracy (on validation data): %0.2f" % accuracy)
    plt.rcParams["figure.figsize"] = (12,10)
    # Output a graph of loss metrics over periods.
    plt.ylabel("LogLoss", fontsize = 20)
    plt.xlabel("Periods", fontsize = 20)
    plt.title("LogLoss vs. Periods (validation)", fontsize = 20)
    plt.plot(validation_errors, 'k', linewidth = 2)
    #plt.legend()
    plt.show()
    
    plt.rcParams["figure.figsize"] = (12,10)
    
    cm = metrics.confusion_matrix(y_test_n, final_predictions)
    # Normalize the confusion matrix by row (i.e by the number of samples
    # in each class).
    cm_normalized = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
    
    ax = sns.heatmap(cm_normalized, cmap="bone_r")
    ax.set_aspect(1)
    plt.title("Confusion matrix", fontsize = 20)
    plt.ylabel("True label", fontsize = 20)
    plt.xlabel("Predicted label", fontsize = 20)
    plt.show()
    
    # Commented out IPython magic to ensure Python compatibility.
    print("Classification report for classifier %s:\n%s\n"
    #       % (model_1, metrics.classification_report(y_test_n, final_predictions, labels=[0, 1])))
    
    accuracy = accuracy_score(y_test_n, final_predictions)
    DNN_C = accuracy
    print('Accuracy: {:.2f}%'.format(DNN_C * 100))
    
    """# DNN
    ## (10, 5, 2)
    """
    
    model_3 = tf.estimator.LinearClassifier(feature_columns=feat_cols, n_classes=2)
    
    model_3 = tf.estimator.DNNClassifier(feature_columns=feat_cols, optimizer = legacy.Adam,
                                              hidden_units=[10, 5, 2],
                                              #dropout=0.025,
                                              #activation_fn = tf.nn.softmax,
                                              #optimizer='Adagrad',
                                              n_classes=2)
    
    print("Training model_3...")
    print("LogLoss error (on validation data):")
    validation_errors = []
    for period in range (0, 200):
    # Train the model_3, starting from the prior state.
        model_3.train(
        input_fn=input_func,
        steps=500
        )
        pred_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)
        y_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=y_test,batch_size=len(y_test),shuffle=False)
    
        validation_predictions = list(model_3.predict(input_fn=pred_fn))
        validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])
        validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])
        validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,0)
        validation_log_loss = metrics.log_loss(y_test_n, validation_pred_one_hot)
        print(" period %02d : %0.2f" % (period, validation_log_loss))
        validation_errors.append(validation_log_loss)
    
    final_predictions = model_3.predict(input_fn=pred_fn)
    final_predictions = np.array([item['class_ids'][0] for item in final_predictions])
    
    accuracy = metrics.accuracy_score(y_test_n, final_predictions)
    print("Final accuracy (on validation data): %0.2f" % accuracy)
    plt.rcParams["figure.figsize"] = (12,10)
    # Output a graph of loss metrics over periods.
    plt.ylabel("LogLoss", fontsize = 20)
    plt.xlabel("Periods", fontsize = 20)
    plt.title("LogLoss vs. Periods (validation)", fontsize = 20)
    plt.plot(validation_errors, 'k', linewidth = 2)
    #plt.legend()
    plt.show()
    
    plt.rcParams["figure.figsize"] = (12,10)
    
    cm = metrics.confusion_matrix(y_test_n, final_predictions)
    # Normalize the confusion matrix by row (i.e by the number of samples
    # in each class).
    cm_normalized = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
    
    ax = sns.heatmap(cm_normalized, cmap="bone_r")
    ax.set_aspect(1)
    plt.title("Confusion matrix", fontsize = 20)
    plt.ylabel("True label", fontsize = 20)
    plt.xlabel("Predicted label", fontsize = 20)
    plt.show()
    
    # Commented out IPython magic to ensure Python compatibility.
    print("Classification report for classifier %s:\n%s\n"
    #       % (model_3, metrics.classification_report(y_test_n, final_predictions, labels=[0, 1])))
    
    accuracy = accuracy_score(y_test_n, final_predictions)
    DNN_D = accuracy
    print('Accuracy: {:.2f}%'.format(DNN_D * 100))
    
    """# SVM
    
    ## SVM with bagging
    """
    
    from sklearn.svm import SVC
    from sklearn.ensemble import BaggingClassifier
    
    svm = SVC(kernel='rbf', gamma='scale')
    bagging_svm = BaggingClassifier(base_estimator=svm, n_estimators=10, random_state=42)
    bagging_svm.fit(X_train, y_train)
    
    y_pred = bagging_svm.predict(X_test)
    
    from sklearn.metrics import classification_report, confusion_matrix
    confusion = print(confusion_matrix(y_test_n, y_pred))
    confusion
    
    print(classification_report(y_test_n, y_pred))
    
    accuracy = accuracy_score(y_test_n, y_pred)
    SVM_with_Bagging = accuracy
    print('Accuracy: {:.2f}%'.format(SVM_with_Bagging * 100))
    
    """## SVM with GridSearchCV"""
    
    from sklearn.model_selection import GridSearchCV
    from sklearn.feature_selection import SelectKBest, f_classif
    
    selector = SelectKBest(score_func=f_classif, k=6)
    X_train_selected = selector.fit_transform(X_train, y_train)
    X_test_selected = selector.transform(X_test)
    
    params = {
        'kernel': ['linear', 'rbf'],
        'C': [0.1, 1, 10],
        'gamma': ['scale', 'auto']
    }
    
    grid = GridSearchCV(SVC(), params, cv=5)
    grid.fit(X_train_selected, y_train)
    
    sv_classifier = grid.best_estimator_
    
    svm_two = sv_classifier.fit(X_train, y_train)
    
    y_pred_svm_two = svm_two.predict(X_test)
    confusion = confusion_matrix(y_test_n, y_pred_svm_two)
    print(confusion)
    
    import seaborn as sns
    sns.heatmap(confusion, annot=True, cmap = 'Greens')
    
    print(classification_report(y_test_n, y_pred_svm_two))
    
    accuracy = accuracy_score(y_test_n, y_pred_svm_two)
    SVM_with_GridSearch = accuracy
    print('Accuracy: {:.2f}%'.format(SVM_with_GridSearch * 100))
    
    """# XG Boost"""
    
    import xgboost as xgb
    
    xg = xgb.XGBClassifier()
    xg.fit(X_train, y_train)
    
    xgb.plot_importance(xg)
    plt.show()
    
    y_pred = xg.predict(X_test)
    
    report = classification_report(y_test, y_pred)
    
    print(report)
    
    accuracy = accuracy_score(y_test, y_pred)
    XGBoost = accuracy
    print('Accuracy: {:.2f}%'.format(XGBoost * 100))
    
    """# Decision Tree"""
    
    from sklearn import tree
    from sklearn.tree import DecisionTreeClassifier
    
    decision = DecisionTreeClassifier(max_depth=3)
    
    decision.fit(X_train, y_train)
    
    y_pred = decision.predict(X_test)
    
    classification_rep = classification_report(y_test, y_pred)
    print(classification_rep)
    
    accuracy = accuracy_score(y_test, y_pred)
    Decision_Tree = accuracy
    print('Accuracy: {:.2f}%'.format(Decision_Tree * 100))
    
    """# Catboost"""
    
    pip install catboost
    
    import catboost
    from catboost import CatBoostClassifier
    
    catboost_classifier = CatBoostClassifier()
    
    catboost_classifier.fit(X_train, y_train)
    
    y_pred_cat = catboost_classifier.predict(X_test)
    cat_heat = confusion_matrix(y_test, y_pred_cat)
    sns.heatmap(cat_heat, annot = True, cmap = 'Greens')
    
    print(classification_report(y_test, y_pred_cat))
    
    accuracy = accuracy_score(y_test, y_pred_cat)
    CatBoost = accuracy
    print('Accuracy: {:.2f}%'.format(CatBoost * 100))
    
    """# Comparison table and plot for different models
    
    
    
    
    
    """
    
    accuracies = {'Models' : ['DNN_(500 X 250 X 100)', 'DNN_(200 X 100 X 50)', 'DNN_(100, 50, 25)', 'DNN_(10 X 5 X 2)', 'SVM_with_Bagging', 'SVM_with_GridSearch', 'XGBoost', 'Decision_Tree', 'CatBoost'],
                  'Accuracies' : [DNN_A*100,DNN_B*100, DNN_C*100, DNN_D*100, SVM_with_Bagging*100, SVM_with_GridSearch*100, XGBoost*100, Decision_Tree*100, CatBoost*100]}
    all_accuracies = pd.DataFrame(accuracies)
    
    sorted_accuracies = all_accuracies.sort_values('Accuracies').reset_index().drop(columns = 'index', axis = 0)
    sorted_accuracies
    
    sns.set_style("whitegrid")
    sns.set(rc={'figure.figsize':(8,6)})
    sns.lineplot(x=sorted_accuracies.index, y='Accuracies', data=sorted_accuracies, marker='o', color='blue', linewidth=2.5)
    
    plt.title('Model Accuracies')
    plt.xlabel('Models')
    plt.ylabel('Accuracy (%)')
    plt.xticks(range(0, 9), sorted_accuracies['Models'], rotation = 68)
    
    plt.show()




